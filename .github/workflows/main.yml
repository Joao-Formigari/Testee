name: Twitter Webscraping

on:
  schedule:
    - cron: "48 * * * *" # Every hour

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    # Load Repo and Install R
    steps:
      - uses: actions/checkout@master
      - uses: r-lib/actions/setup-r@master 
      
      
      # Set-up R
      - name: Install Packages
        run: |
          sudo apt install libcurl4-openssl-dev
          R -e 'install.packages("dplyr")'
          R -e 'install.packages("academictwitteR")'
          
      # Run Rscript    
      - name: Scraping
        run: R/hello.R
        
      # Add new files in folders and commit
      #- name: Commit
        #run: |
          #git config --local user.name github-actions
          #git config --local user.email "actions@github.com"
          #git add --all
          #git commit -am "add Data"
          #git push
        #env:
          #REPO_KEY: ${{secrets.GITHUB_TOKEN}}
          #username: github-actions
